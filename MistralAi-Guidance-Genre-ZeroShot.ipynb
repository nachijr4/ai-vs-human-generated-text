{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14841f0b-3d1f-4667-8c73-c135b18fada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"A Cowboy Who Rode the Waves\",\"Car free cities\",\"Cell phones at school\",\"Community service\",\"Distance learning\",\"Does the electoral college work\",\"Driverless cars\",\"Exploring Venus\",\"Facial action coding system\",\"Mandatory extracurricular activities\",\"Phones and driving\",\"Seeking multiple opinions\",\"Summer projects\",\"The Face on Mars\"]\n",
    "category = \"The Face on Mars\"\n",
    "input_file = \"/scratch1/avuthu/category_split/test_\"+category+\".csv\"\n",
    "output_file = \"/scratch1/avuthu/zero_shot_mistral_category_predictions/predictions_\"+category+\".txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b7df259-c0e4-401d-b1b0-71fe54a4f6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/avuthu/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home1/avuthu/.local/lib/python3.9/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [02:03<00:00, 61.80s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import guidance\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "#model = \"sinking8/mixtral_finetuned\"\n",
    "temp = 0.01\n",
    "guidance.llm = guidance.llms.Transformers(model, device=device, temperature=temp)\n",
    "\n",
    "#The function `process_input_text` processes a given text, calls a function `structure_program` on it, and tries to extract an 'answer'\n",
    "#from the output. If it doesn't find an 'answer', it retries until it does, while managing memory during this process.\n",
    "# The log probs value for two classes seems to be negative at certain instances and the label that corresponds to the maximum among those is given as an output by guidance.\n",
    "# To convert the classifier to regressor the abs difference between the log probs are taken assuming that 1 -> Supportive 0-> Unsupportive and passing it to the sigmoid layer.\n",
    "def process_input_text(prompt_text, structure_program):\n",
    "    answer = None\n",
    "    while answer is None:\n",
    "        out = structure_program(prompt_text=prompt_text)\n",
    "        try:\n",
    "            answer = out['answer']\n",
    "        except KeyError:\n",
    "            print(\"Key 'answer' not found in the output. Retrying...\")\n",
    "            #print(out.variables())\n",
    "            import gc\n",
    "            gc.collect()\n",
    "            import torch\n",
    "            torch.cuda.empty_cache()\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e464b4b2-0eeb-49d0-b1bf-cc720484dd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1893\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(input_file)\n",
    "input_prompts = data['text'].tolist()\n",
    "true_labels=data[\"label\"].tolist()\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31b483cc-ee5b-48a0-a6ba-97cfdacc3729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can only run 1000 queries at a time. After that need to restart the kernel on CARC\n",
    "start=0\n",
    "stop=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "807d84cc-6aa8-421b-9c2c-51dd2847e5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "\n",
    "import torch\n",
    "import warnings\n",
    "def run_code(model, prompt, temp):\n",
    "    structure_program = guidance(prompt)    \n",
    "    for i, t in enumerate(input_prompts[start:stop]):\n",
    "        label = process_input_text(t,structure_program)\n",
    "        labels.append(label)\n",
    "    with open(output_file, 'a') as file:\n",
    "    #Write each label followed by a newline character\n",
    "        for label in labels:\n",
    "            file.write(label + '\\n')\n",
    "    file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "768cbfef-cc15-4a39-8a1c-651d655f9452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"guidance-stop-button-ab01e676-1ff5-4639-bfde-66114de6e482\" style=\"cursor: pointer; margin: 0px; display: none; float: right; padding: 3px; border-radius: 4px 4px 4px 4px; border: 0px solid rgba(127, 127, 127, 1); padding-left: 10px; padding-right: 10px; font-size: 13px; background-color: rgba(127, 127, 127, 0.25);\">Stop program</div><div id=\"guidance-content-ab01e676-1ff5-4639-bfde-66114de6e482\"><pre style='margin: 0px; padding: 0px; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'>Is the given following prompt AI generated? Answer with a single word, either &quot;yes&quot; or &quot;no&quot;.\n",
       "    Prompt: <span style='background-color: rgba(0, 138.56128016, 250.76166089, 0.25); display: inline;' title='{{prompt_text}}'> I remember the first time I saw the Face on Mars. It was a hazy summer day, and my colleague and I were discussing our latest research findings over a cup of coffee in the NASA control room. My colleague lowered his cup and pointed to the large screen television in the corner. &quot;Look at that,&quot; he said, his eyes wide as saucers. \n",
       "\n",
       "I turned to see a grainy photograph of a rocky surface covered in craters and odd-shaped mounds. And then I saw it. In the middle of the frame, looming over the surrounding landscape, was a gigantic rock formation shaped like a human face, complete with a distinct jawline and a pair of hollow eyes. I nearly dropped my coffee cup. \n",
       "\n",
       "&quot;That&#x27;s the Face on Mars,&quot; my colleague said, sounding equally stunned. \n",
       "\n",
       "I had heard of the Face on Mars, of course, but I had never seen it up close like this. I leaned in for a closer look, and that&#x27;s when I noticed something strange. The image was blurry and grainy, but as I looked closer, I could see that the &quot;eyes&quot; of the Face were actually just two sunken pits in the rock, not unlike the craters that covered the rest of the planet&#x27;s surface. \n",
       "\n",
       "&quot;It&#x27;s a natural landform,&quot; I said, feeling a surge of excitement as the pieces of the puzzle began to fall into place. &quot;The light and shadows must have created the illusion of a face.&quot; \n",
       "\n",
       "My colleague shook his head. &quot;But what about the size of it? It&#x27;s huge! Nothing natural could create a formation like that.&quot; \n",
       "\n",
       "I smiled. &quot;Nature creates some pretty amazing things,&quot; I said. &quot;But in this case, the shape of the rock, the lighting, and the shadows must have all combined to create the illusion of a face. It&#x27;s just like the Nazca Lines in Peru.&quot; \n",
       "\n",
       "My colleague looked unconvinced. &quot;But what about the eyes? They look like they were made by something else, something intelligent.&quot; \n",
       "\n",
       "I smiled. &quot;Nature is intelligent,&quot; I said. &quot;The eyes are just two pits in the rock that happen to be shaped in a way that resembles eyes. It&#x27;s an amazing phenomenon, and it&#x27;s a perfect example of how nature can create something that looks like it was made by something else.&quot; \n",
       "\n",
       "My colleague nodded slowly. &quot;I see your point,&quot; he said. &quot;But it&#x27;s still a little bit freaky.&quot; \n",
       "\n",
       "I laughed. &quot;It&#x27;s all a matter of perspective,&quot; I said. &quot;But the next time you see the Face on Mars, remember that it&#x27;s just a natural landform, and there&#x27;s no need to worry about aliens.&quot; \n",
       "\n",
       "I walked back to my desk, still feeling a bit amazed at the power of nature to create such an eerie phenomenon. But as I sat down and got back to work, I couldn&#x27;t help but feel a sense of respect for the incredible diversity of the planet we call home. </span>\n",
       "    Answer:<span style='background-color: rgba(0, 165, 0, 0.25); opacity: 1.0; display: inline;' title='{{#select &quot;answer&quot; logprobs=&#x27;logprobs&#x27;}} Yes{{or}} No{{/select}}'> Yes No No</span></pre></div>\n",
       "<script type=\"text/javascript\">(()=>{var t={296:(t,e,n)=>{var i=NaN,o=\"[object Symbol]\",r=/^\\s+|\\s+$/g,a=/^[-+]0x[0-9a-f]+$/i,s=/^0b[01]+$/i,c=/^0o[0-7]+$/i,d=parseInt,u=\"object\"==typeof n.g&&n.g&&n.g.Object===Object&&n.g,l=\"object\"==typeof self&&self&&self.Object===Object&&self,f=u||l||Function(\"return this\")(),h=Object.prototype.toString,p=Math.max,m=Math.min,g=function(){return f.Date.now()};function b(t){var e=typeof t;return!!t&&(\"object\"==e||\"function\"==e)}function y(t){if(\"number\"==typeof t)return t;if(function(t){return\"symbol\"==typeof t||function(t){return!!t&&\"object\"==typeof t}(t)&&h.call(t)==o}(t))return i;if(b(t)){var e=\"function\"==typeof t.valueOf?t.valueOf():t;t=b(e)?e+\"\":e}if(\"string\"!=typeof t)return 0===t?t:+t;t=t.replace(r,\"\");var n=s.test(t);return n||c.test(t)?d(t.slice(2),n?2:8):a.test(t)?i:+t}t.exports=function(t,e,n){var i,o,r,a,s,c,d=0,u=!1,l=!1,f=!0;if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");function h(e){var n=i,r=o;return i=o=void 0,d=e,a=t.apply(r,n)}function v(t){var n=t-c;return void 0===c||n>=e||n<0||l&&t-d>=r}function _(){var t=g();if(v(t))return w(t);s=setTimeout(_,function(t){var n=e-(t-c);return l?m(n,r-(t-d)):n}(t))}function w(t){return s=void 0,f&&i?h(t):(i=o=void 0,a)}function j(){var t=g(),n=v(t);if(i=arguments,o=this,c=t,n){if(void 0===s)return function(t){return d=t,s=setTimeout(_,e),u?h(t):a}(c);if(l)return s=setTimeout(_,e),h(c)}return void 0===s&&(s=setTimeout(_,e)),a}return e=y(e)||0,b(n)&&(u=!!n.leading,r=(l=\"maxWait\"in n)?p(y(n.maxWait)||0,e):r,f=\"trailing\"in n?!!n.trailing:f),j.cancel=function(){void 0!==s&&clearTimeout(s),d=0,i=c=o=s=void 0},j.flush=function(){return void 0===s?a:w(g())},j}},777:t=>{var e,n,i=Math.max,o=(e=function(t,e){return function(t,e,n){if(\"function\"!=typeof t)throw new TypeError(\"Expected a function\");return setTimeout((function(){t.apply(void 0,n)}),1)}(t,0,e)},n=i(void 0===n?e.length-1:n,0),function(){for(var t=arguments,o=-1,r=i(t.length-n,0),a=Array(r);++o<r;)a[o]=t[n+o];o=-1;for(var s=Array(n+1);++o<n;)s[o]=t[o];return s[n]=a,function(t,e,n){switch(n.length){case 0:return t.call(e);case 1:return t.call(e,n[0]);case 2:return t.call(e,n[0],n[1]);case 3:return t.call(e,n[0],n[1],n[2])}return t.apply(e,n)}(e,this,s)});t.exports=o}},e={};function n(i){var o=e[i];if(void 0!==o)return o.exports;var r=e[i]={exports:{}};return t[i](r,r.exports,n),r.exports}n.n=t=>{var e=t&&t.__esModule?()=>t.default:()=>t;return n.d(e,{a:e}),e},n.d=(t,e)=>{for(var i in e)n.o(e,i)&&!n.o(t,i)&&Object.defineProperty(t,i,{enumerable:!0,get:e[i]})},n.g=function(){if(\"object\"==typeof globalThis)return globalThis;try{return this||new Function(\"return this\")()}catch(t){if(\"object\"==typeof window)return window}}(),n.o=(t,e)=>Object.prototype.hasOwnProperty.call(t,e),(()=>{\"use strict\";const t=t=>{const e=new Set;do{for(const n of Reflect.ownKeys(t))e.add([t,n])}while((t=Reflect.getPrototypeOf(t))&&t!==Object.prototype);return e};function e(e,{include:n,exclude:i}={}){const o=t=>{const e=e=>\"string\"==typeof e?t===e:e.test(t);return n?n.some(e):!i||!i.some(e)};for(const[n,i]of t(e.constructor.prototype)){if(\"constructor\"===i||!o(i))continue;const t=Reflect.getOwnPropertyDescriptor(n,i);t&&\"function\"==typeof t.value&&(e[i]=e[i].bind(e))}return e}var i=n(777),o=n.n(i),r=n(296),a=n.n(r);class s{constructor(t,n){e(this),this.interfaceId=t,this.callbackMap={},this.data={},this.pendingData={},this.jcomm=new c(\"guidance_interface_target_\"+this.interfaceId,this.updateData,\"open\"),this.debouncedSendPendingData500=a()(this.sendPendingData,500),this.debouncedSendPendingData1000=a()(this.sendPendingData,1e3),n&&o()(n)}send(t,e){this.addPendingData(t,e),this.sendPendingData()}sendEvent(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.sendPendingData()}debouncedSendEvent500(t){for(const e of Object.keys(t))this.addPendingData(e,t[e]);this.debouncedSendPendingData500()}debouncedSend500(t,e){this.addPendingData(t,e),this.debouncedSendPendingData500()}debouncedSend1000(t,e){this.addPendingData(t,e),this.debouncedSendPendingData1000()}addPendingData(t,e){Array.isArray(t)||(t=[t]);for(const n in t)this.pendingData[t[n]]=e}updateData(t){t=JSON.parse(t.data);for(const e in t)this.data[e]=t[e];for(const e in t)e in this.callbackMap&&this.callbackMap[e](this.data[e])}subscribe(t,e){this.callbackMap[t]=e,o()((e=>this.callbackMap[t](this.data[t])))}sendPendingData(){this.jcomm.send_data(this.pendingData),this.pendingData={}}}class c{constructor(t,e,n=\"open\"){this._fire_callback=this._fire_callback.bind(this),this._register=this._register.bind(this),this.jcomm=void 0,this.callback=e,void 0!==window.Jupyter?\"register\"===n?Jupyter.notebook.kernel.comm_manager.register_target(t,this._register):(this.jcomm=Jupyter.notebook.kernel.comm_manager.new_comm(t),this.jcomm.on_msg(this._fire_callback)):void 0!==window._mgr&&(\"register\"===n?window._mgr.widgetManager.proxyKernel.registerCommTarget(t,this._register):(this.jcomm=window._mgr.widgetManager.proxyKernel.createComm(t),this.jcomm.open({},\"\"),this.jcomm.onMsg=this._fire_callback))}send_data(t){void 0!==this.jcomm?this.jcomm.send(t):console.error(\"Jupyter comm module not yet loaded! So we can't send the message.\")}_register(t,e){this.jcomm=t,this.jcomm.on_msg(this._fire_callback)}_fire_callback(t){this.callback(t.content.data)}}class d{constructor(t,n){e(this),this.id=t,this.comm=new s(t),this.comm.subscribe(\"append\",this.appendData),this.comm.subscribe(\"replace\",this.replaceData),this.comm.subscribe(\"event\",this.eventOccurred),this.element=document.getElementById(\"guidance-content-\"+t),this.stop_button=document.getElementById(\"guidance-stop-button-\"+t),this.stop_button.onclick=()=>this.comm.send(\"event\",\"stop\")}appendData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML+=t)}replaceData(t){t&&(this.stop_button.style.display=\"inline-block\",this.element.innerHTML=t)}eventOccurred(t){\"complete\"===t&&(this.stop_button.style.display=\"none\")}}window._guidanceDisplay=function(t,e){return new d(t,e)}})()})();; window._guidanceDisplay(\"ab01e676-1ff5-4639-bfde-66114de6e482\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Run the main script\n",
    "import time\n",
    "start_time=time.time()\n",
    "model = \"mistralai/Mistral-7B-Instruct-v0.1\" #huggingface model\n",
    "temperature = 0.02 #the lower the more deterministic\n",
    "prompt = '''Is the given following prompt AI generated? Answer with a single word, either \"yes\" or \"no\".\n",
    "    Prompt: {{prompt_text}}\n",
    "    Answer:{{#select \"answer\" logprobs='logprobs'}} Yes{{or}} No{{/select}}'''\n",
    "run_code(model,prompt,temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af918259-9ec5-493d-9688-72c15496c698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1893\n"
     ]
    }
   ],
   "source": [
    "file = open(output_file, \"r\")\n",
    "data = file.readlines() \n",
    "predicted_labels=[]\n",
    "for line in data:\n",
    "    if(line.strip()==\"No\"):\n",
    "        predicted_labels.append(0)\n",
    "    else:\n",
    "        predicted_labels.append(1)\n",
    "file.close() \n",
    "print(len(predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69e9f536-d4c0-45ce-8032-ffc2b4e7b712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1893\n"
     ]
    }
   ],
   "source": [
    "print(len(true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3e05312-d090-4c7d-9ed8-55f09be15afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Face on Mars 0.12321428571428572 0.22258064516129034 0.15862068965517243\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "def calculate_metrics(true_labels, predicted_labels):\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "    return precision, recall, f1\n",
    "precision_value, recall_value, f1_score_value = calculate_metrics(true_labels, predicted_labels)\n",
    "print(category,precision_value, recall_value, f1_score_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avuthu_python_kernel",
   "language": "python",
   "name": "avuthu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
